{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import skimage.registration as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ar\n",
    "import invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def read_avi_file(path: str) -> np.ndarray:\n",
    "    \"\"\"Reads an .avi file and returns a stack of frames.\"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))  # Convert BGR to RGB\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "vid = read_avi_file(path=r\"D:\\chp\\1001-8.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 480, 640)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "maximum supported dimension for an ndarray is 32, found 1164",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read in a video.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# vid = np.load(\"../data/wavy.npy\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m vid \u001b[38;5;241m=\u001b[39m \u001b[43mread_avi_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mchp\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m1001-8.avi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(vid\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mread_avi_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     13\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY))  \u001b[38;5;66;03m# Convert BGR to RGB\u001b[39;00m\n\u001b[0;32m     15\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 1164"
     ]
    }
   ],
   "source": [
    "# Read in a video.\n",
    "# vid = np.load(\"../data/wavy.npy\")\n",
    "vid = read_avi_file(path = r\"D:\\chp\\1001-8.avi\")\n",
    "print(vid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vid[0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute optical flow.\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.calcOpticalFlowFarneback(\n",
    "#  frame1,\n",
    "#  frame2,\n",
    "#  prevFlow,\n",
    "#  pyr_scale = 0.5,\n",
    "#  levels = 3 (number of pyramid levels),\n",
    "#  winsize = 30 (larger = more robust but also blurrier),\n",
    "#  iterations = 10 (number of iterations at each layer),\n",
    "#  poly_n = 5 (larger is more robust but blurrier),\n",
    "#  poly_sigma = 1.1 (size of gaussian blur),\n",
    "#  flags = cv2.OPTFLOW_USE_INITIAL_FLOW & cv2.OPTFLOW_FARNEBACK_GAUSSIAN\n",
    "# )\n",
    "\n",
    "#opt = cv2.calcOpticalFlowFarneback(vid[0], vid[1], np.zeros(shape = vid[0].shape), 0.5, 3, 30, 10, 7, 1.5, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, step=6):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
    "    fx, fy = flow[y,x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact  # Where the magic happens with ipywidgets.\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_video(video):\n",
    "    n_frames = video.shape[0]\n",
    "    \n",
    "    # This is our callback function, and what makes the widget possible.\n",
    "    def _show(frame = 1):\n",
    "        return Image.fromarray(video[frame - 1])\n",
    "    \n",
    "    return interact(_show, frame = (1, n_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1163/1163 [07:51<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "flow_vid = []\n",
    "rot = []\n",
    "\n",
    "prev_flow = None\n",
    "for i in tqdm(range(1, vid.shape[0])):\n",
    "    curr = vid[i]\n",
    "    prev = vid[i - 1]\n",
    "    \n",
    "    opt = cv2.calcOpticalFlowFarneback(\n",
    "        prev,\n",
    "        curr,\n",
    "        prev_flow, \n",
    "        0.75, # pyr_scale\n",
    "        7,   # levels\n",
    "        15,  # winsize\n",
    "        20,  # iterations\n",
    "        7,   # poly_n\n",
    "        0.9, # poly_sigma\n",
    "        cv2.OPTFLOW_FARNEBACK_GAUSSIAN & cv2.OPTFLOW_USE_INITIAL_FLOW\n",
    "    )\n",
    "    opt = np.array(opt, dtype = np.float64)\n",
    "    rot.append(invariants.curl(opt[:, :, 0], opt[:, :, 1]))\n",
    "    flow_vid.append(draw_flow(curr, opt))\n",
    "    prev_flow = opt\n",
    "flow_vid = np.array(flow_vid)\n",
    "rot = np.array(rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video(np.array(flow_vid[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwrot = rot.copy()\n",
    "bwrot += np.abs(bwrot.min())\n",
    "bwrot /= bwrot.max()\n",
    "bwrot *= 256\n",
    "bwrot = np.array(bwrot, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video(bwrot[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.abs(bwrot.max(axis = 0) - bwrot.min(axis = 0))\n",
    "diff = scipy.signal.medfilt2d(diff, kernel_size = 11)\n",
    "plt.imshow(diff, cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diff.flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = rot[:, 125:160, 40:60]\n",
    "raster = patch.reshape((patch.shape[0], -1))\n",
    "plt.plot(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spq.ar as ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [01:44<00:00,  4.60it/s]\n"
     ]
    }
   ],
   "source": [
    "order = 5\n",
    "\n",
    "image = np.zeros(shape = (order, rot.shape[1], rot.shape[2]))\n",
    "for row in tqdm(range(image.shape[1])):\n",
    "    for col in range(image.shape[2]):\n",
    "        a = ar.train(rot[:, row, col], order)\n",
    "        for i in range(image.shape[0]):\n",
    "            image[i, row, col] = a[i][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import raster_scan\n",
    "X = raster_scan(rot).T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 12))\n",
    "for i in range(order):\n",
    "    plt.subplot(1, order, i + 1)\n",
    "    plt.title(\"$a_{}$\".format(i + 1))\n",
    "    plt.imshow(image[i], cmap = \"Blues\", vmin = image.min(), vmax = image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(image[0].flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.mixture as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = skm.GaussianMixture(n_components = 2, random_state = 42)\n",
    "y = gmm.fit_predict(image[0].flatten().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(image[0].shape), cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(image[1].flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = skm.GaussianMixture(n_components = 2, random_state = 42)\n",
    "y = gmm.fit_predict(image[1].flatten().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(image[1].shape), cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(image[2].flatten(), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = skm.GaussianMixture(n_components = 2, random_state = 42)\n",
    "y = gmm.fit_predict(image[2].flatten().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(image[2].shape), cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = np.array(y, dtype = np.uint8)\n",
    "mask = yb.reshape(image[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((image.shape[1], image.shape[2], 3), dtype = np.uint8)\n",
    "for index in range(3):\n",
    "    channel = image[index].copy()\n",
    "    channel -= channel.min()\n",
    "    channel /= channel.max()\n",
    "    channel *= 255\n",
    "    img[:, :, index] = np.array(channel, dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgModel = np.zeros((1, 65), dtype = np.float64)\n",
    "bgModel = np.zeros((1, 65), dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mask, bgModel, fgModel) = cv2.grabCut(img, mask, None, bgModel, fgModel, \n",
    "                                       iterCount = 200, mode = cv2.GC_INIT_WITH_MASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask, cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a different video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"wavy_ar.npy\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a video.\n",
    "div = np.load(\"data/videos/stiff_dyskinetic.npy\")\n",
    "print(div.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_vid = []\n",
    "drot = []\n",
    "\n",
    "prev_flow = None\n",
    "for i in tqdm(range(1, div.shape[0])):\n",
    "    curr = div[i]\n",
    "    prev = div[i - 1]\n",
    "    \n",
    "    opt = cv2.calcOpticalFlowFarneback(\n",
    "        prev,\n",
    "        curr,\n",
    "        prev_flow, \n",
    "        0.85, # pyr_scale\n",
    "        7,   # levels\n",
    "        15,  # winsize\n",
    "        20,  # iterations\n",
    "        7,   # poly_n\n",
    "        0.7, # poly_sigma\n",
    "        cv2.OPTFLOW_FARNEBACK_GAUSSIAN & cv2.OPTFLOW_USE_INITIAL_FLOW\n",
    "    )\n",
    "    opt = np.array(opt, dtype = np.float64)\n",
    "    drot.append(invariants.curl(opt[:, :, 0], opt[:, :, 1]))\n",
    "    flow_vid.append(draw_flow(curr, opt))\n",
    "    prev_flow = opt\n",
    "flow_vid = np.array(flow_vid)\n",
    "drot = np.array(drot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwrot = drot.copy()\n",
    "bwrot += np.abs(bwrot.min())\n",
    "bwrot /= bwrot.max()\n",
    "bwrot *= 256\n",
    "bwrot = np.array(bwrot, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video(bwrot[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimage = np.zeros(shape = (order, drot.shape[1], drot.shape[2]))\n",
    "for row in tqdm(range(dimage.shape[1])):\n",
    "    for col in range(dimage.shape[2]):\n",
    "        a = ar.train(drot[:, row, col], order)\n",
    "        dimage[:, row, col] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 12))\n",
    "for i in range(order):\n",
    "    plt.subplot(1, order, i + 1)\n",
    "    plt.title(\"$a_{}$\".format(i + 1))\n",
    "    plt.imshow(dimage[i], cmap = \"Blues\", vmin = dimage.min(), vmax = dimage.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"stiff_dyskinetic_AR.npy\", dimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"normal_AR.npy\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"wavy_AR.npy\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cilia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
